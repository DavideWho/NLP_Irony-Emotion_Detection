{"cells":[{"cell_type":"markdown","metadata":{"id":"Y5KhTfzHc82I"},"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24781,"status":"ok","timestamp":1736519302630,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"-RxSVWZfPBf_","outputId":"c6b65d7e-25d9-4d99-8df9-2e7e8236d599"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12231,"status":"ok","timestamp":1736519314859,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"mEkgirnEPQ9M","outputId":"28eeaea7-b222-41cc-e11c-d09976d15a6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: nltk 3.9.1\n","Uninstalling nltk-3.9.1:\n","  Successfully uninstalled nltk-3.9.1\n","Collecting nltk\n","  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex\u003e=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n","Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nltk\n","Successfully installed nltk-3.9.1\n","Collecting emoji\n","  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n","Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-2.14.0\n"]}],"source":["!pip uninstall -y nltk\n","!pip install --upgrade nltk\n","!pip install emoji"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31973,"status":"ok","timestamp":1736519346830,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"Q6PQzsJAN63t","outputId":"411207c7-18b9-4a04-8f14-fca695bee2a3"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk import word_tokenize, pos_tag\n","from transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW, get_scheduler\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","from torch import nn\n","from torch.optim import Adam\n","from tqdm import tqdm\n","import emoji\n","\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","nltk.download('averaged_perceptron_tagger_eng')\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2490,"status":"ok","timestamp":1736519349318,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"-fr0KV2zPbtv"},"outputs":[],"source":["root = '/content/drive/MyDrive/NLP/Davide/irony_davide_datasets/'\n","\n","x_train = pd.read_csv(root + 'x_train.csv')\n","x_test = pd.read_csv(root + 'x_test.csv')\n","x_val = pd.read_csv(root + 'x_val.csv')\n","y_train = pd.read_csv(root + 'y_train.csv')\n","y_test = pd.read_csv(root + 'y_test.csv')\n","y_val = pd.read_csv(root + 'y_val.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1736519349319,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"8xBXFIfzaJeU"},"outputs":[],"source":["hyperparameters = {\n","    \"epochs\": 18,\n","    \"learning_rate\": 2e-5,   #1e-5\n","    \"batch_size\": 8,  #accura...\n","    \"dropout\": 0.3,   # o 0.3\n","    \"weight_decay\": 5e-4,  #1e-3\n","    \"stopwords\": False,\n","    \"language_model\": \"bert-base-uncased\",\n","    \"layers\": 1,\n","    \"h_dim\": 768,\n","    \"bilstm\": False,\n","    \"patience\": 5,\n","    \"min_delta\": 0.01,\n","    \"extra_features\": 5\n","}\n","\n","param_grid = {\n","    \"learning_rate\": [1e-5, 2e-5, 5e-5],\n","    \"dropout\": [0.3, 0.5],\n","    \"weight_decay\": [1e-5, 5e-4]\n","}"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1736519349319,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"zVZdes9oODcg","outputId":"34c96ecc-cf83-43f7-fc09-9df33b898718"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["nltk.download('punkt')\n","nltk.download('punkt_tab')\n","nltk.download('stopwords')\n","\n","class Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, x, hashtag_count, avg_ironic_ratio, ironic_hashtag_count, non_ironic_hashtag_count, hashtag_irony_index, y, stopwords):  #nn_count\n","        # x e y sono series di pandas\n","        tokens_litt = [nltk.word_tokenize(text, language='english') for text in list(x)]\n","        text_clean = []\n","\n","        if stopwords:\n","            for sentence in tqdm(tokens_litt, desc='Tokenizing ... '):\n","                text_clean.append(' '.join([w.lower() for w in sentence if\n","                                            not w.lower() in nltk.corpus.stopwords.words(\"english\")]))\n","        else:\n","            for sentence in tqdm(tokens_litt, desc='Tokenizing ... '):\n","                text_clean.append(' '.join([w.lower() for w in sentence]))\n","            # ogni token è separato dall'altro con uno spazio\n","\n","        self.texts = text_clean\n","        self.labels = [torch.tensor(label) for label in y]\n","        #self.emoji_count = [torch.tensor(count) for count in emoji_count]\n","        #self.ironic_emoji = [torch.tensor(ironic) for ironic in ironic_emoji]\n","        #self.non_ironic_emoji = [torch.tensor(non_ironic) for non_ironic in non_ironic_emoji]\n","        #self.nn_count = [torch.tensor(count) for count in nn_count]  # Nuova colonna\n","        self.hashtag_count = [torch.tensor(count) for count in hashtag_count]\n","        self.avg_ironic_ratio = [torch.tensor(ratio) for ratio in avg_ironic_ratio]\n","        self.ironic_hashtag_count = [torch.tensor(count) for count in ironic_hashtag_count]\n","        self.non_ironic_hashtag_count = [torch.tensor(count) for count in non_ironic_hashtag_count]\n","        self.hashtag_irony_index = [torch.tensor(index) for index in hashtag_irony_index]\n","\n","    def classes(self):\n","        return self.labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        batch_texts = self.texts[idx]\n","        batch_labels = np.array(self.labels[idx])\n","        #batch_emoji_count = np.array(self.emoji_count[idx])\n","        #batch_ironic_emoji = np.array(self.ironic_emoji[idx])\n","        #batch_non_ironic_emoji = np.array(self.non_ironic_emoji[idx])\n","        #batch_nn_count = np.array(self.nn_count[idx])  # Aggiunto NN_count\n","        batch_hashtag_count = np.array(self.hashtag_count[idx])\n","        batch_avg_ironic_ratio = np.array(self.avg_ironic_ratio[idx])\n","        batch_ironic_hashtag_count = np.array(self.ironic_hashtag_count[idx])\n","        batch_non_ironic_hashtag_count = np.array(self.non_ironic_hashtag_count[idx])\n","        batch_hashtag_irony_index = np.array(self.hashtag_irony_index[idx])\n","\n","        return batch_texts, batch_hashtag_count, batch_avg_ironic_ratio, batch_ironic_hashtag_count, batch_non_ironic_hashtag_count, batch_hashtag_irony_index, batch_labels\n","        #batch_emoji_count, batch_ironic_emoji, batch_non_ironic_emoji, batch_nn_count\n","\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":345,"status":"ok","timestamp":1736519349661,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"33wUwS-Cdosc","outputId":"99f76640-915f-4e4a-b524-c808152e956e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"x_train\",\n  \"rows\": 1717,\n  \"fields\": [\n    {\n      \"column\": \"hashtag_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          12,\n          10,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_ironic_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36920875020074534,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          0.8,\n          0.7604166666666666,\n          0.7916666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ironic_hashtag_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1,\n          4,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"non_ironic_hashtag_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          11,\n          10,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hashtag_irony_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8178711131552885,\n        \"min\": 0.0,\n        \"max\": 8.833333333333332,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          0.5833333333333333,\n          1.7,\n          2.0666666666666664\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1717,\n        \"samples\": [\n          \"#Fears #for #female #Saudi #activist as #detention for #driving a #car is #extended via @user \\n\",\n          \"Thanks Mother nature.. You didn't give us as snow day and now my twitter is filled with people complaining  \\n\",\n          \"I just love when you test my patience! :smiling_face:  \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"x_train"},"text/html":["\n","  \u003cdiv id=\"df-1e47701e-b133-4ce7-8847-0c8d21591b61\" class=\"colab-df-container\"\u003e\n","    \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ehashtag_count\u003c/th\u003e\n","      \u003cth\u003eavg_ironic_ratio\u003c/th\u003e\n","      \u003cth\u003eironic_hashtag_count\u003c/th\u003e\n","      \u003cth\u003enon_ironic_hashtag_count\u003c/th\u003e\n","      \u003cth\u003ehashtag_irony_index\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e@user not surprised, it was epic. \\n\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003eSooo mad right now, great way to start my day  \\n\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003eLol well done swans  \\n\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","      \u003ctd\u003e@user thanks for the wake up wrap and coffee t...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003eSo excited to spend the next 12 hours at schoo...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1712\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003eAy after 2 hours nareceive ko rin yung message...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1713\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e@user Alone Tonight cause its a personal song ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1714\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003eA year ago this would be just a writing on a t...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1715\u003c/th\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e@user @user yeah \u0026amp; we wont talk about how the ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1716\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e@user gotta love how honest kids are. #saywhat...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e1717 rows × 6 columns\u003c/p\u003e\n","\u003c/div\u003e\n","    \u003cdiv class=\"colab-df-buttons\"\u003e\n","\n","  \u003cdiv class=\"colab-df-container\"\u003e\n","    \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e47701e-b133-4ce7-8847-0c8d21591b61')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\"\u003e\n","    \u003cpath d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","\n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","    \u003cscript\u003e\n","      const buttonEl =\n","        document.querySelector('#df-1e47701e-b133-4ce7-8847-0c8d21591b61 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1e47701e-b133-4ce7-8847-0c8d21591b61');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","\n","\u003cdiv id=\"df-333ace7f-abe1-4432-9503-3c334622c915\"\u003e\n","  \u003cbutton class=\"colab-df-quickchart\" onclick=\"quickchart('df-333ace7f-abe1-4432-9503-3c334622c915')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\"\u003e\n","\n","\u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\"\u003e\n","    \u003cg\u003e\n","        \u003cpath d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/\u003e\n","    \u003c/g\u003e\n","\u003c/svg\u003e\n","  \u003c/button\u003e\n","\n","\u003cstyle\u003e\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","\u003c/style\u003e\n","\n","  \u003cscript\u003e\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() =\u003e {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-333ace7f-abe1-4432-9503-3c334622c915 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  \u003c/script\u003e\n","\u003c/div\u003e\n","\n","  \u003cdiv id=\"id_51750c2a-1d9d-4a59-a7b7-90a6bda37d06\"\u003e\n","    \u003cstyle\u003e\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    \u003c/style\u003e\n","    \u003cbutton class=\"colab-df-generate\" onclick=\"generateWithVariable('x_train')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","    \u003cscript\u003e\n","      (() =\u003e {\n","      const buttonEl =\n","        document.querySelector('#id_51750c2a-1d9d-4a59-a7b7-90a6bda37d06 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () =\u003e {\n","        google.colab.notebook.generateWithVariable('x_train');\n","      }\n","      })();\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n"],"text/plain":["      hashtag_count  avg_ironic_ratio  ironic_hashtag_count  \\\n","0                 0               0.0                     0   \n","1                 0               0.0                     0   \n","2                 0               0.0                     0   \n","3                 1               1.0                     1   \n","4                 0               0.0                     0   \n","...             ...               ...                   ...   \n","1712              0               0.0                     0   \n","1713              1               0.0                     0   \n","1714              1               0.0                     0   \n","1715              0               0.0                     0   \n","1716              1               0.0                     0   \n","\n","      non_ironic_hashtag_count  hashtag_irony_index  \\\n","0                            0                  0.0   \n","1                            0                  0.0   \n","2                            0                  0.0   \n","3                            0                  1.0   \n","4                            0                  0.0   \n","...                        ...                  ...   \n","1712                         0                  0.0   \n","1713                         1                  0.0   \n","1714                         1                  0.0   \n","1715                         0                  0.0   \n","1716                         1                  0.0   \n","\n","                                                   text  \n","0                  @user not surprised, it was epic. \\n  \n","1     Sooo mad right now, great way to start my day  \\n  \n","2                               Lol well done swans  \\n  \n","3     @user thanks for the wake up wrap and coffee t...  \n","4     So excited to spend the next 12 hours at schoo...  \n","...                                                 ...  \n","1712  Ay after 2 hours nareceive ko rin yung message...  \n","1713  @user Alone Tonight cause its a personal song ...  \n","1714  A year ago this would be just a writing on a t...  \n","1715  @user @user yeah \u0026 we wont talk about how the ...  \n","1716  @user gotta love how honest kids are. #saywhat...  \n","\n","[1717 rows x 6 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["x_train"]},{"cell_type":"markdown","metadata":{"id":"2qiMe9wkPdkz"},"source":[]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1742,"status":"ok","timestamp":1736519351401,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"ElhQQnd4Z27l","outputId":"bb441990-fe2c-499a-aed1-0d1dcc74152a"},"outputs":[{"name":"stderr","output_type":"stream","text":["Tokenizing ... : 100%|██████████| 1717/1717 [00:00\u003c00:00, 82272.26it/s]\n","Tokenizing ... : 100%|██████████| 916/916 [00:00\u003c00:00, 62157.94it/s]\n","Tokenizing ... : 100%|██████████| 229/229 [00:00\u003c00:00, 14146.57it/s]\n"]}],"source":["train_dataset = Dataset(x_train['text'], x_train['hashtag_count'], x_train['avg_ironic_ratio'], x_train['ironic_hashtag_count'], x_train['non_ironic_hashtag_count'], x_train['hashtag_irony_index'], y_train.squeeze(1), hyperparameters[\"stopwords\"])\n","val_dataset = Dataset(x_val['text'], x_val['hashtag_count'], x_val['avg_ironic_ratio'], x_val['ironic_hashtag_count'], x_val['non_ironic_hashtag_count'], x_val['hashtag_irony_index'], y_val.squeeze(1), hyperparameters[\"stopwords\"])\n","test_dataset = Dataset(x_test['text'], x_test['hashtag_count'], x_test['avg_ironic_ratio'], x_test['ironic_hashtag_count'], x_test['non_ironic_hashtag_count'], x_test['hashtag_irony_index'], y_test.squeeze(1), hyperparameters[\"stopwords\"])\n","\n","#val_dataset = Dataset(x_val['text'], x_val['emoji_count'], x_val['has_ironic_emoji'], x_val['has_non_ironic_emoji'], x_val['NN_count'], y_val.squeeze(1), hyperparameters[\"stopwords\"])\n","#test_dataset = Dataset(x_test['text'], x_test['emoji_count'], x_test['has_ironic_emoji'], x_test['has_non_ironic_emoji'], x_test['NN_count'], y_test.squeeze(1), hyperparameters[\"stopwords\"])"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1736519351401,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"NyAtahwyZ2Il"},"outputs":[],"source":["class EarlyStopping:\n","    def __init__(self, patience=5, min_delta=0.0):\n","\n","        self.patience = patience\n","        self.min_delta = min_delta              # valore minimo di decrescita della loss di validazione all'epoca corrente\n","                                                # per asserire che c'è un miglioramenti della loss\n","        self.counter = 0                        # contatore delle epoche di pazienza\n","        self.early_stop = False                 # flag di early stop\n","        self.min_validation_loss = torch.inf    # valore corrente ottimo della loss di validazione\n","\n","    def __call__(self, validation_loss):\n","        # chiamata in forma funzionale dell'oggetto di classe EarlySopping\n","\n","        if (validation_loss + self.min_delta) \u003e= self.min_validation_loss:  # la loss di validazione non decresce\n","            self.counter += 1                                               # incrementiamo il contatore delle epoche di pazienza\n","            if self.counter \u003e= self.patience:\n","                self.early_stop = True\n","                print(\"Early stop!\")\n","        else:                                               # c'è un miglioramento della loss:\n","            self.min_validation_loss = validation_loss      # consideriamo la loss corrente\n","                                                            # come nuova loss ottimale\n","            self.counter = 0                                # e azzeriamo il contatore di pazienza\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1736519351401,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"PUHJ5LoDoPev"},"outputs":[],"source":["class ClassifierDeep(nn.Module):\n","\n","    def __init__(self, hdim, dropout, model_name, extra_features = hyperparameters[\"extra_features\"]):\n","        super(ClassifierDeep, self).__init__()\n","        config = AutoConfig.from_pretrained(model_name)\n","        self.lm_model = AutoModel.from_pretrained(model_name, config=config)\n","\n","        self.classifier = nn.Sequential(\n","          nn.Linear(hdim + extra_features, hdim),\n","          nn.BatchNorm1d(hdim),\n","          nn.Dropout(dropout),\n","          nn.ReLU(),\n","          nn.Linear(hdim, 16),\n","          nn.BatchNorm1d(16),\n","          nn.Dropout(dropout),\n","          nn.ReLU(),\n","          nn.Linear(16, 1),\n","          nn.Sigmoid()\n","          )\n","\n","\n","\n","\n","    #def forward(self, input_id_text, attention_mask, emoji_count, has_ironic_emoji, has_non_ironic_emoji, nn_count):\n","    def forward(self, input_id_text, attention_mask, hashtag_count, avg_ironic_ratio, ironic_hashtag_count, non_ironic_hashtag_count, hashtag_irony_index):\n","        output = self.lm_model(input_id_text, attention_mask).last_hidden_state\n","        output = output[:,0,:]\n","        #output = torch.cat((output, emoji_count.unsqueeze(1), has_ironic_emoji.unsqueeze(1), has_non_ironic_emoji.unsqueeze(1), nn_count.unsqueeze(1)), dim=1)\n","        output = torch.cat((output, hashtag_count.unsqueeze(1), avg_ironic_ratio.unsqueeze(1), ironic_hashtag_count.unsqueeze(1), non_ironic_hashtag_count.unsqueeze(1), hashtag_irony_index.unsqueeze(1)), dim=1)\n","        return self.classifier(output)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1736519351401,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"rU8RtKwO8tN0"},"outputs":[],"source":["def train_loop(model, dataloader, tokenizer, loss, optimizer, device, scheduler):\n","    model.train()\n","\n","    epoch_acc = 0\n","    epoch_loss = 0\n","\n","    #for batch_texts, batch_emoji_count, batch_ironic_emoji, batch_non_ironic_emoji, batch_nn_count, batch_labels in tqdm(dataloader, desc='training set'):\n","    for batch_texts, batch_hashtag_count, batch_avg_ironic_ratio, batch_ironic_hashtag_count, batch_non_ironic_hashtag_count, batch_hashtag_irony_index, batch_labels in tqdm(dataloader, desc='training set'):\n","\n","        optimizer.zero_grad()\n","\n","        tokens = tokenizer(list(batch_texts),\n","                           add_special_tokens=True,\n","                           return_tensors='pt',\n","                           padding='max_length',\n","                           max_length = 256,\n","                           truncation=True)\n","\n","        input_id_texts = tokens['input_ids'].squeeze(1).to(device)\n","        mask_texts = tokens['attention_mask'].squeeze(1).to(device)\n","        #batch_emoji_count = batch_emoji_count.float().to(device)\n","        #batch_ironic_emoji = batch_ironic_emoji.float().to(device)\n","        #batch_non_ironic_emoji = batch_non_ironic_emoji.float().to(device)\n","        #batch_nn_count = batch_nn_count.float().to(device)\n","        batch_hashtag_count = batch_hashtag_count.float().to(device)\n","        batch_avg_ironic_ratio = batch_avg_ironic_ratio.float().to(device)\n","        batch_ironic_hashtag_count = batch_ironic_hashtag_count.float().to(device)\n","        batch_non_ironic_hashtag_count = batch_non_ironic_hashtag_count.float().to(device)\n","        batch_hashtag_irony_index = batch_hashtag_irony_index.float().to(device)\n","        batch_labels = batch_labels.float().to(device)\n","\n","\n","        #output = model(input_id_texts, mask_texts, batch_emoji_count, batch_ironic_emoji, batch_non_ironic_emoji, batch_nn_count).squeeze(1)\n","        output = model(input_id_texts, mask_texts, batch_hashtag_count, batch_avg_ironic_ratio, batch_ironic_hashtag_count, batch_non_ironic_hashtag_count, batch_hashtag_irony_index).squeeze(1)\n","\n","        # la loss è una CrossEntropyLoss, al suo interno ha\n","        # la logsoftmax + negative log likelihood loss\n","        batch_loss = loss(output, batch_labels)\n","        batch_loss.backward()\n","        ##### GRADIENT CLIPPING #####\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        #############################\n","        optimizer.step()\n","\n","        ###### SCHEDULER ######\n","        # Scheduler step\n","        scheduler.step()\n","        print(optimizer.param_groups[0][\"lr\"])\n","        #######################\n","\n","        epoch_loss += batch_loss.item()\n","\n","        # per calcolare l'accuracy devo generare le predizioni\n","        # applicando manualmente la logsoftmax\n","        preds = (output \u003e 0.5).float()  # Soglia di 0.5 per la classificazione binaria\n","        epoch_acc += (preds == batch_labels).sum().item()\n","\n","        batch_labels = batch_labels.detach().cpu()\n","        input_id_texts = input_id_texts.detach().cpu()\n","        mask_texts = mask_texts.detach().cpu()\n","        #batch_emoji_count = batch_emoji_count.detach().cpu()\n","        #batch_ironic_emoji = batch_ironic_emoji.detach().cpu()\n","        #batch_non_ironic_emoji = batch_non_ironic_emoji.detach().cpu()\n","        #batch_nn_count = batch_nn_count.detach().cpu()\n","        batch_hashtag_count = batch_hashtag_count.detach().cpu()\n","        batch_avg_ironic_ratio = batch_avg_ironic_ratio.detach().cpu()\n","        batch_ironic_hashtag_count = batch_ironic_hashtag_count.detach().cpu()\n","        batch_non_ironic_hashtag_count = batch_non_ironic_hashtag_count.detach().cpu()\n","        batch_hashtag_irony_index = batch_hashtag_irony_index.detach().cpu()\n","        output = output.detach().cpu()\n","\n","\n","    return epoch_loss/len(dataloader), epoch_acc\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1736519351401,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"r1yFWCCu-Pah"},"outputs":[],"source":["def test_loop(model, dataloader, tokenizer, loss, device):\n","    model.eval()\n","\n","    epoch_acc = 0\n","    epoch_loss = 0\n","\n","    with torch.no_grad():\n","\n","        #for batch_texts, batch_emoji_count, batch_ironic_emoji, batch_non_ironic_emoji, batch_nn_count, batch_labels in tqdm(dataloader, desc='dev set'):\n","        for batch_texts, batch_hashtag_count, batch_avg_ironic_ratio, batch_ironic_hashtag_count, batch_non_ironic_hashtag_count, batch_hashtag_irony_index, batch_labels in tqdm(dataloader, desc='dev set'):\n","\n","            tokens = tokenizer(list(batch_texts),\n","                               add_special_tokens=True,\n","                               return_tensors='pt',\n","                               padding='max_length',\n","                               max_length = 256,\n","                               truncation=True)\n","            input_id_texts = tokens['input_ids'].squeeze(1).to(device)\n","            mask_texts = tokens['attention_mask'].squeeze(1).to(device)\n","            #batch_emoji_count = batch_emoji_count.float().to(device)\n","            #batch_ironic_emoji = batch_ironic_emoji.float().to(device)\n","            #batch_non_ironic_emoji = batch_non_ironic_emoji.float().to(device)\n","            #batch_nn_count = batch_nn_count.float().to(device)\n","            batch_hashtag_count = batch_hashtag_count.float().to(device)\n","            batch_avg_ironic_ratio = batch_avg_ironic_ratio.float().to(device)\n","            batch_ironic_hashtag = batch_ironic_hashtag_count.float().to(device)\n","            batch_non_ironic_hashtag = batch_non_ironic_hashtag_count.float().to(device)\n","            batch_hashtag_irony_index = batch_hashtag_irony_index.float().to(device)\n","            batch_labels = batch_labels.float().to(device)\n","\n","            #output = model(input_id_texts, mask_texts, batch_emoji_count, batch_ironic_emoji, batch_non_ironic_emoji, batch_nn_count).squeeze(1)\n","            output = model(input_id_texts, mask_texts, batch_hashtag_count, batch_avg_ironic_ratio, batch_ironic_hashtag, batch_non_ironic_hashtag, batch_hashtag_irony_index).squeeze(1)\n","\n","            # la loss è una CrossEntropyLoss, al suo interno ha\n","            # la logsoftmax + negative log likelihood loss\n","            batch_loss = loss(output, batch_labels)\n","            epoch_loss += batch_loss.item()\n","\n","            # per calcolare l'accuracy devo generare le predizioni\n","            # applicando manualmente la logsoftmax\n","            preds = (output \u003e 0.5).float()  # Soglia di 0.5 per la classificazione binaria\n","            epoch_acc += (preds == batch_labels).sum().item()\n","\n","            batch_labels = batch_labels.detach().cpu()\n","            input_id_texts = input_id_texts.detach().cpu()\n","            mask_texts = mask_texts.detach().cpu()\n","            #batch_emoji_count = batch_emoji_count.detach().cpu()\n","            #batch_ironic_emoji = batch_ironic_emoji.detach().cpu()\n","            #batch_non_ironic_emoji = batch_non_ironic_emoji.detach().cpu()\n","            #batch_nn_count = batch_nn_count.detach().cpu()\n","            batch_hashtag_count = batch_hashtag_count.detach().cpu()\n","            batch_avg_ironic_ratio = batch_avg_ironic_ratio.detach().cpu()\n","            batch_ironic_hashtag = batch_ironic_hashtag.detach().cpu()\n","            batch_non_ironic_hashtag = batch_non_ironic_hashtag.detach().cpu()\n","            batch_hashtag_irony_index = batch_hashtag_irony_index.detach().cpu()\n","            output = output.detach().cpu()\n","\n","    return epoch_loss/len(dataloader), epoch_acc"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1736519351401,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"fO1WVAgVWssY"},"outputs":[],"source":["def unfreeze_layers(model, freeze_up_to_layer):\n","    # Itera su tutti i parametri del modello\n","    for name, param in model.named_parameters():\n","        # Gestisce l'encoder e altri componenti\n","        if 'encoder.layer' in name:\n","            # Estrai il numero del layer\n","            try:\n","                layer_number = int(name.split('.')[2])  # esempio \"encoder.layer.11.attention.self.query.weight\"\n","            except ValueError:\n","                continue  # salta se non riesci a ottenere il numero del layer\n","\n","            # Congela i parametri fino al livello specificato\n","            if layer_number \u003c freeze_up_to_layer:\n","                param.requires_grad = False\n","            else:\n","                param.requires_grad = True\n","\n","        # Gestione degli embeddings (se vuoi congelarli o meno)\n","        elif 'embeddings' in name:\n","            param.requires_grad = False  # Congela gli embeddings (o cambia se vuoi sbloccarli)\n","\n","        # Gestione della parte del pooler e della testa di classificazione (se devi allenare queste parti)\n","        elif 'pooler' in name or 'classifier' in name:\n","            param.requires_grad = True  # Assicurati che questi componenti siano allenati\n","\n","        # Stampa dello stato di \"requires_grad\" per ogni parametro\n","        print(f\"{name} - requires_grad = {param.requires_grad}\")\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1736519351401,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"Z7OPTRm6TqBk"},"outputs":[],"source":["def train_test(model, epochs, optimizer, device, train_data, test_data,\n","               batch_size, model_name, train_loss_fn,\n","               test_loss_fn=None,         # non necessariamente train e test loss devono differire\n","               early_stopping=None,       # posso addstrare senza early stopping\n","               val_data=None,             # e in questo caso non c'è validation set\n","               scheduler=None,            # possibile scheduler per monitorare l'andamento di un iperparametro\n","               freeze_every_n_epochs=5,  # il numero di epoche dopo le quali sbloccare i layer\n","               freeze_up_to_layer=8):    # il numero di layer iniziali da congelare\n","\n","    # Congelamento progressivo all'inizio\n","    unfreeze_layers(model, freeze_up_to_layer)\n","\n","    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n","    val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n","    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n","\n","    # check sulle funzioni di loss\n","    if test_loss_fn == None:\n","        test_loss_fn = train_loss_fn\n","\n","    # liste dei valori di loss e accuracy epoca per epoca per il plot\n","    train_loss = []\n","    validation_loss = []\n","    test_loss = []\n","    train_acc = []\n","    validation_acc = []\n","    test_acc = []\n","\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    all_emojis = list(emoji.EMOJI_DATA.keys())\n","    emoji_tokens = [emoji.demojize(e) for e in all_emojis]\n","    tokenizer.add_tokens(emoji_tokens)\n","    tokenizer.add_tokens([\"@user\"])\n","    model.lm_model.resize_token_embeddings(len(tokenizer))\n","\n","    # Ciclo di addestramento con early stopping\n","    for epoch in tqdm(range(1,epochs+1)):\n","\n","        epoch_train_loss, epoch_train_acc = train_loop(model, train_dataloader, tokenizer, train_loss_fn, optimizer, device, scheduler)\n","        train_loss.append(epoch_train_loss)\n","        train_acc.append(epoch_train_acc/len(train_data))\n","\n","        # Validation se è presente la callback di early stopping\n","        if early_stopping != None:\n","            epoch_validate_loss, epoch_validate_acc = test_loop(model, val_dataloader, tokenizer, test_loss_fn, device)\n","            validation_loss.append(epoch_validate_loss)\n","            validation_acc.append(epoch_validate_acc/len(val_data))\n","\n","        # Test\n","        epoch_test_loss, epoch_test_acc = test_loop(model, test_dataloader, tokenizer, test_loss_fn, device)\n","        test_loss.append(epoch_test_loss)\n","        test_acc.append(epoch_test_acc/len(test_data))\n","\n","        val_loss_str = f'Validation loss: {epoch_validate_loss:6.4f} 'if early_stopping != None else ' '\n","        val_acc_str = f'Validation accuracy: {(epoch_validate_acc/len(val_data)):6.4f} ' if early_stopping != None else ' '\n","        print(f\"\\nTrain loss: {epoch_train_loss:6.4f} {val_loss_str} Test loss: {epoch_test_loss:6.4f}\")\n","        print(f\"Train accuracy: {(epoch_train_acc/len(train_data)):6.4f} {val_acc_str}Test accuracy: {(epoch_test_acc/len(test_data)):6.4f}\")\n","\n","        # Early stopping\n","        if early_stopping != None:\n","            early_stopping(epoch_validate_loss)\n","            if early_stopping.early_stop:\n","                break\n","\n","        # Sblocca i layer ogni 'freeze_every_n_epochs'\n","        if epoch % freeze_every_n_epochs == 0:\n","            freeze_up_to_layer = max(0, freeze_up_to_layer - 1)  # Sblocca un layer\n","            unfreeze_layers(model, freeze_up_to_layer)\n","\n","    return train_loss, validation_loss, test_loss, train_acc, validation_acc, test_acc\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":17968,"status":"ok","timestamp":1736519369366,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"h7s_f8sGdHF6","outputId":"b32f315a-1c70-4f46-b17c-e39cab3270a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu device\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"353f620a633b4e70abd4a1ccd5c3d3b7","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2e9640abef14e49bcb9b2a66ec494f3","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["ClassifierDeep(\n","  (lm_model): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=773, out_features=768, bias=True)\n","    (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): Dropout(p=0.3, inplace=False)\n","    (3): ReLU()\n","    (4): Linear(in_features=768, out_features=16, bias=True)\n","    (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): Dropout(p=0.3, inplace=False)\n","    (7): ReLU()\n","    (8): Linear(in_features=16, out_features=1, bias=True)\n","    (9): Sigmoid()\n","  )\n",")\n","Numbero totale dei parametri: 110090561\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using {device} device\")\n","\n","model = ClassifierDeep(\n","                    hyperparameters[\"h_dim\"],\n","                    hyperparameters[\"dropout\"],\n","                    hyperparameters[\"language_model\"]).to(device)\n","print(model)\n","\n","# Calcoliamo il numero totale dei parametri del modello\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Numbero totale dei parametri: {total_params}\")\n","\n","criterion = nn.BCELoss()\n","optimizer = AdamW(model.parameters(), lr=hyperparameters['learning_rate'], weight_decay=hyperparameters['weight_decay'])\n","\n","###### Linear Warmup + Decay ######\n","# Calcolo dei passi totali\n","total_steps = len(train_dataset) // hyperparameters['batch_size'] * hyperparameters['epochs']\n","\n","# Passi di warmup (ad esempio, 10% del totale)\n","warmup_steps = int(0.1 * total_steps)\n","\n","# Creazione del scheduler\n","scheduler = get_scheduler(\n","    name=\"cosine\",  # Tipo di scheduler   ---\u003e PROVARE COSINE ---\u003e provare con OTTIMIZZATORE SGD INVECE CHE ADAM\n","    optimizer=optimizer,  # Ottimizzatore che stai usando\n","    num_warmup_steps=warmup_steps,\n","    num_training_steps=total_steps\n",")\n","###################################\n","\n","\n","# Creiamo la callback di early stopping da passare al nostro metodo di addestramento\n","early_stopping = EarlyStopping(patience=hyperparameters['patience'], min_delta=hyperparameters['min_delta'])"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1736519369366,"user":{"displayName":"Davide Sgroi","userId":"11889222768285529626"},"user_tz":-60},"id":"k21QobgGdK_B"},"outputs":[],"source":["!export CUDA_LAUNCH_BLOCKING=1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"U3YfvmxKSpc9"},"outputs":[{"name":"stdout","output_type":"stream","text":["lm_model.embeddings.word_embeddings.weight - requires_grad = False\n","lm_model.embeddings.position_embeddings.weight - requires_grad = False\n","lm_model.embeddings.token_type_embeddings.weight - requires_grad = False\n","lm_model.embeddings.LayerNorm.weight - requires_grad = False\n","lm_model.embeddings.LayerNorm.bias - requires_grad = False\n","lm_model.pooler.dense.weight - requires_grad = True\n","lm_model.pooler.dense.bias - requires_grad = True\n","classifier.0.weight - requires_grad = True\n","classifier.0.bias - requires_grad = True\n","classifier.1.weight - requires_grad = True\n","classifier.1.bias - requires_grad = True\n","classifier.4.weight - requires_grad = True\n","classifier.4.bias - requires_grad = True\n","classifier.5.weight - requires_grad = True\n","classifier.5.bias - requires_grad = True\n","classifier.8.weight - requires_grad = True\n","classifier.8.bias - requires_grad = True\n","lm_model.embeddings.word_embeddings.weight - requires_grad = False\n","lm_model.embeddings.position_embeddings.weight - requires_grad = False\n","lm_model.embeddings.token_type_embeddings.weight - requires_grad = False\n","lm_model.embeddings.LayerNorm.weight - requires_grad = False\n","lm_model.embeddings.LayerNorm.bias - requires_grad = False\n","lm_model.pooler.dense.weight - requires_grad = True\n","lm_model.pooler.dense.bias - requires_grad = True\n","classifier.0.weight - requires_grad = True\n","classifier.0.bias - requires_grad = True\n","classifier.1.weight - requires_grad = True\n","classifier.1.bias - requires_grad = True\n","classifier.4.weight - requires_grad = True\n","classifier.4.bias - requires_grad = True\n","classifier.5.weight - requires_grad = True\n","classifier.5.bias - requires_grad = True\n","classifier.8.weight - requires_grad = True\n","classifier.8.bias - requires_grad = True\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff80118057fb4643af1a521c8b6e0dc0","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aea0408468e5442c888653d26c0b758d","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6acb73fae8dd42eeb28deaf110bc319d","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","  0%|          | 0/18 [00:00\u003c?, ?it/s]\n","training set:   0%|          | 0/214 [00:00\u003c?, ?it/s]\u001b[A\n","training set:   0%|          | 1/214 [00:29\u003c1:46:17, 29.94s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   1%|          | 2/214 [00:53\u003c1:33:04, 26.34s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   1%|▏         | 3/214 [01:16\u003c1:27:07, 24.78s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   2%|▏         | 4/214 [01:38\u003c1:23:03, 23.73s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   2%|▏         | 5/214 [02:02\u003c1:22:09, 23.59s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   3%|▎         | 6/214 [02:27\u003c1:23:23, 24.05s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   3%|▎         | 7/214 [02:50\u003c1:22:46, 23.99s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   4%|▎         | 8/214 [03:12\u003c1:19:54, 23.27s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   4%|▍         | 9/214 [03:36\u003c1:19:58, 23.41s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   5%|▍         | 10/214 [03:58\u003c1:17:49, 22.89s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   5%|▌         | 11/214 [04:21\u003c1:17:33, 22.93s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   6%|▌         | 12/214 [04:43\u003c1:16:58, 22.87s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   6%|▌         | 13/214 [05:05\u003c1:15:30, 22.54s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   7%|▋         | 14/214 [05:29\u003c1:16:26, 22.93s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   7%|▋         | 15/214 [05:52\u003c1:15:59, 22.91s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   7%|▋         | 16/214 [06:17\u003c1:17:40, 23.54s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   8%|▊         | 17/214 [06:40\u003c1:17:07, 23.49s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   8%|▊         | 18/214 [07:04\u003c1:17:20, 23.68s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]},{"name":"stderr","output_type":"stream","text":["\n","training set:   9%|▉         | 19/214 [07:26\u003c1:14:47, 23.02s/it]\u001b[A"]},{"name":"stdout","output_type":"stream","text":["2e-05\n"]}],"source":["# Congela i layer fino al numero specificato\n","freeze_up_to_layer = 4\n","unfreeze_layers(model, freeze_up_to_layer)\n","\n","# Recupera i parametri che richiedono il calcolo del gradiente (i parametri non congelati)\n","params_to_train = [param for param in model.parameters() if param.requires_grad]\n","\n","# Verifica se ci sono parametri da allenare\n","if len(params_to_train) == 0:\n","  raise ValueError(\"Non ci sono parametri da allenare. Verifica che il congelamento e sblocco dei layer siano corretti.\")\n","\n","# Creazione dell'ottimizzatore con i parametri non congelati\n","optimizer = torch.optim.Adam(params_to_train, lr=hyperparameters['learning_rate'])\n","\n","# Ora puoi chiamare la routine di addestramento\n","train_loss, validation_loss, test_loss, train_acc, validation_acc, test_acc = train_test(\n","  model,\n","  hyperparameters['epochs'],\n","  optimizer,  # Ora passa l'ottimizzatore configurato\n","  device,\n","  train_dataset,\n","  test_dataset,\n","  hyperparameters['batch_size'],\n","  hyperparameters['language_model'],\n","  criterion,\n","  criterion,  # o qualsiasi altra loss\n","  early_stopping,\n","  val_dataset,\n","  scheduler=scheduler\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BMvXitWEexOz"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aS_AAnCbdQ3J"},"outputs":[],"source":["'''\n","import matplotlib.pyplot as plt\n","fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n","\n","  axs[0].plot(train_loss, label='training loss')\n","  axs[0].plot(validation_loss, label='validation loss')\n","  axs[0].plot(test_loss, label='test loss')\n","  axs[0].legend(loc='upper right')\n","  axs[0].set_ylim(0,1)\n","\n","  axs[1].plot(train_acc, label='training accuracy')\n","  axs[1].plot(validation_acc, label='validation accuracy')\n","  axs[1].plot(test_acc, label='test accuracy')\n","  axs[1].legend(loc='lower right')\n","  axs[1].set_ylim(0,1)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"02b911d694b64dfeac251792807ce508":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0691cfc0df9f4b978b1ddfb7fac585c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08aa6cf1d46c41d58769554c2a7768d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12fc4fe830fb4fdaa33c00fdf09c5564":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a8800ac3fdf42eab3b57d087675fb87","placeholder":"​","style":"IPY_MODEL_5642a696c9f044e4b6153bec12d1f4ca","value":" 570/570 [00:00\u0026lt;00:00, 8.53kB/s]"}},"13101690dec64df89b7e41d08b5771ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13ca53193d354cdc8163ffd0cf9c45dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95913ade89d34f9493c624ffe6e6fe94","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0691cfc0df9f4b978b1ddfb7fac585c8","value":466062}},"186603e725f54943afecb1eb00024710":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13101690dec64df89b7e41d08b5771ee","placeholder":"​","style":"IPY_MODEL_f8f301b86bd14306a0e4eb66e97e0d1a","value":"config.json: 100%"}},"19670bb62b59470b9600714eeece6a45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a9d688fa7e74603bd05d6b79c776b51","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa16c7cd1c7d4e8b9497ff42a4e4c47e","value":570}},"1a9d688fa7e74603bd05d6b79c776b51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c2dc041e113424db1f28dc71912453d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fd4bfc550424b10a52f1b0bdc5f2d1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2248febd12274b8e87f576d102d8688c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26a1f067491d46279ef8bb0b1766dc3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e1535cac67d45b79d17c0b72fa63791":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b3557aa581045a8a4720ed5ec06b90a","placeholder":"​","style":"IPY_MODEL_36f8416325784e7790d3a95eeec110b6","value":"vocab.txt: 100%"}},"2fa4ed75d8244aca8bd88670485d186c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fc04e600bcf49b0bd49869d82fd52a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"300e5b3a18414f1190558aa39d2d69ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31c56a4cb66e44639842ff28f44975d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"353f620a633b4e70abd4a1ccd5c3d3b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_186603e725f54943afecb1eb00024710","IPY_MODEL_19670bb62b59470b9600714eeece6a45","IPY_MODEL_12fc4fe830fb4fdaa33c00fdf09c5564"],"layout":"IPY_MODEL_c27cd19ba392448aa4560dc7048c4e8f"}},"36f8416325784e7790d3a95eeec110b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"377bbbc9eaa24516ad72c3ce29a9e659":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38cf16b101f7468eb71fdc662642e9a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a8800ac3fdf42eab3b57d087675fb87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ba4bdc379794e9e8eced43cf197fe45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fc04e600bcf49b0bd49869d82fd52a0","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2248febd12274b8e87f576d102d8688c","value":48}},"479b10201d4d4d7cabd564e9a9d3de7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1a9f7ad14f5442fa0e2807f3fdd9bb1","placeholder":"​","style":"IPY_MODEL_bbcca2d2f7da4905b424ca48d39e1f3c","value":"tokenizer_config.json: 100%"}},"48f6a3b20d794341be19e2ff03420dd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_377bbbc9eaa24516ad72c3ce29a9e659","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38cf16b101f7468eb71fdc662642e9a2","value":440449768}},"508e534f15d14d6e835c23688aa734e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55dcb336d31b406eb9c2ee785a49f62d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5642a696c9f044e4b6153bec12d1f4ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"668360229c0c4feabbeea7a4cf1cf387":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6acb73fae8dd42eeb28deaf110bc319d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e2ed46bca4245e59595fafd18427cdc","IPY_MODEL_13ca53193d354cdc8163ffd0cf9c45dc","IPY_MODEL_6b9ce2193cce4e51a6432222fe5f5d51"],"layout":"IPY_MODEL_02b911d694b64dfeac251792807ce508"}},"6b3557aa581045a8a4720ed5ec06b90a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b9ce2193cce4e51a6432222fe5f5d51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_668360229c0c4feabbeea7a4cf1cf387","placeholder":"​","style":"IPY_MODEL_891606c2e8fb4e719d822b9c12d0f2b7","value":" 466k/466k [00:00\u0026lt;00:00, 4.57MB/s]"}},"700f184ca90b4a1eb5858242ae0d90dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31c56a4cb66e44639842ff28f44975d6","placeholder":"​","style":"IPY_MODEL_1fd4bfc550424b10a52f1b0bdc5f2d1c","value":" 440M/440M [00:04\u0026lt;00:00, 127MB/s]"}},"891606c2e8fb4e719d822b9c12d0f2b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e2ed46bca4245e59595fafd18427cdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c264546e21904e0ca818a884f884cc69","placeholder":"​","style":"IPY_MODEL_97e44bee0b9847ef90d7930c04ec2ecd","value":"tokenizer.json: 100%"}},"95913ade89d34f9493c624ffe6e6fe94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96b914a7b1e14e258ad91f06c00856a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97e44bee0b9847ef90d7930c04ec2ecd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa16c7cd1c7d4e8b9497ff42a4e4c47e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aea0408468e5442c888653d26c0b758d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e1535cac67d45b79d17c0b72fa63791","IPY_MODEL_b55c7e059d4342cb97df65d781ef7172","IPY_MODEL_e3f23876f4d34b6fac8b5f0b1aba5345"],"layout":"IPY_MODEL_d5740b86c934478598aa72013519efd7"}},"b55c7e059d4342cb97df65d781ef7172":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c2dc041e113424db1f28dc71912453d","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e514bbbf8c0f4778a579517dd39be9e2","value":231508}},"bbcca2d2f7da4905b424ca48d39e1f3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be711c2a4ba24aa3ae83706fac4f74d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08aa6cf1d46c41d58769554c2a7768d6","placeholder":"​","style":"IPY_MODEL_96b914a7b1e14e258ad91f06c00856a6","value":"model.safetensors: 100%"}},"c264546e21904e0ca818a884f884cc69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c27cd19ba392448aa4560dc7048c4e8f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2e9640abef14e49bcb9b2a66ec494f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be711c2a4ba24aa3ae83706fac4f74d6","IPY_MODEL_48f6a3b20d794341be19e2ff03420dd6","IPY_MODEL_700f184ca90b4a1eb5858242ae0d90dc"],"layout":"IPY_MODEL_300e5b3a18414f1190558aa39d2d69ed"}},"d5740b86c934478598aa72013519efd7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1a9f7ad14f5442fa0e2807f3fdd9bb1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3f23876f4d34b6fac8b5f0b1aba5345":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_508e534f15d14d6e835c23688aa734e4","placeholder":"​","style":"IPY_MODEL_eadee50957bf4f2faa238ec47a595234","value":" 232k/232k [00:00\u0026lt;00:00, 2.02MB/s]"}},"e514bbbf8c0f4778a579517dd39be9e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eadee50957bf4f2faa238ec47a595234":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f09098ddf9ae48edbd83665612962185":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26a1f067491d46279ef8bb0b1766dc3c","placeholder":"​","style":"IPY_MODEL_2fa4ed75d8244aca8bd88670485d186c","value":" 48.0/48.0 [00:00\u0026lt;00:00, 764B/s]"}},"f8f301b86bd14306a0e4eb66e97e0d1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff80118057fb4643af1a521c8b6e0dc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_479b10201d4d4d7cabd564e9a9d3de7d","IPY_MODEL_3ba4bdc379794e9e8eced43cf197fe45","IPY_MODEL_f09098ddf9ae48edbd83665612962185"],"layout":"IPY_MODEL_55dcb336d31b406eb9c2ee785a49f62d"}}}}},"nbformat":4,"nbformat_minor":0}