{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJkk1Yc2tHO7",
        "outputId": "be2c548f-829f-4025-8e47-0f32d7c1526a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/590.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m583.7/590.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "!pip install emoji\n",
        "import emoji\n",
        "import re\n",
        "import sklearn\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "import torch\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW\n",
        "from transformers import DebertaV2Tokenizer\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5CXsTiKouS81",
        "outputId": "6457f390-ec56-402b-9894-c219df14a527"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  “Worry is a down payment on a problem you may ...      2\n",
              "1  My roommate: it's okay that we can't spell bec...      0\n",
              "2  No but that's so cute. Atsu was probably shy a...      1\n",
              "3  Rooneys fucking untouchable isn't he? Been fuc...      0\n",
              "4  it's pretty depressing when u hit pan on ur fa...      3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d4b29a5-d848-4a52-900c-e2df42073aa6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Worry is a down payment on a problem you may ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rooneys fucking untouchable isn't he? Been fuc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it's pretty depressing when u hit pan on ur fa...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d4b29a5-d848-4a52-900c-e2df42073aa6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8d4b29a5-d848-4a52-900c-e2df42073aa6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8d4b29a5-d848-4a52-900c-e2df42073aa6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9cc47c66-581a-445d-8ae5-8c68f5dc41d8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9cc47c66-581a-445d-8ae5-8c68f5dc41d8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9cc47c66-581a-445d-8ae5-8c68f5dc41d8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 3257,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3232,\n        \"samples\": [\n          \"@user Yeah, but bad part is the #terrorism #terror Muslims won't be the ones leaving #ObamaLegacy #nationalsecurity #disaster #Obama\",\n          \"I feel like an appendix. I don't have a purpose. #sad #depressed #depression #alone #lonely #broken #sadness #cry #hurt #crying #life\",\n          \"I start work tmrw yall, i'm nervous lol\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#Creazione dataset, la prima colonna è il testo intero del tweet\n",
        "\n",
        "datas = \"/content/drive/MyDrive/NLP/Challenge_2024/emotion/train_text.txt\"\n",
        "with open(datas, 'r', encoding='utf-8') as f:\n",
        "    tweets = f.readlines()\n",
        "\n",
        "# Rimuovi eventuali spazi vuoti o newline\n",
        "tweets = [tweet.strip() for tweet in tweets]\n",
        "\n",
        "# Crea un DataFrame\n",
        "data = pd.DataFrame(tweets, columns=['text'])\n",
        "\n",
        "labels =\"/content/drive/MyDrive/NLP/Challenge_2024/emotion/train_labels.txt\"\n",
        "with open(labels, 'r', encoding='utf-8') as f:\n",
        "    labels = f.readlines()\n",
        "\n",
        "labels2 = [int(label.strip()) for label in labels]\n",
        "\n",
        "data.insert(1, \"label\", labels2)\n",
        "texts = pd.DataFrame(data, columns=[\"text\"])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC4cIdXeu2xd",
        "outputId": "aea6276c-83a2-4629-dc79-316147356093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3257 entries, 0 to 3256\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    3257 non-null   object\n",
            " 1   label   3257 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 51.0+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "74eQYzKzu6U-",
        "outputId": "4fb787e2-c921-43e0-a391-62a127038869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "samples -> 3257\n",
            "categories -> {0, 1, 2, 3}[4]\n",
            "label\n",
            "0    1400\n",
            "3     855\n",
            "1     708\n",
            "2     294\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='label'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Utilizzo il bert-model-cased per il task di classificazione\n",
        "#0 = Rabbia\n",
        "#1 = Gioia\n",
        "#2 = Ottimismo\n",
        "#3 = Tristezza\n",
        "print('samples -> '+str(len(data)))\n",
        "labels = set(data['label'])\n",
        "numLabels = len(labels)\n",
        "print('categories -> '+str(labels)+'['+str(len(labels))+']')\n",
        "print(data['label'].value_counts())\n",
        "data.groupby(['label']).size().plot.bar()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(lm_model_base, token=hf_auth)\n",
        "model = AutoModelForCausalLM.from_pretrained(lm_model_base, token=hf_auth)\n",
        "device = 'cuda'\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "def paraphrase_text(text, max_length=100):\n",
        "    \"\"\"Genera una parafrasi usando LLaMA 2\"\"\"\n",
        "    if not isinstance(text, str) or text.strip() == \"\":\n",
        "        return text  # Evita errori con valori mancanti\n",
        "\n",
        "    prompt = f\"Parafrasa la seguente frase mantenendo il significato: '{text}'\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")  # Usa GPU se disponibile\n",
        "\n",
        "    outputs = model.generate(**inputs, max_length=max_length, temperature=0.7, top_k=50, top_p=0.95)\n",
        "    paraphrased_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return paraphrased_text.replace(prompt, \"\").strip()  # Rimuove il prompt dal risultato\n",
        "\n",
        "# Carichiamo il dataset\n",
        "file_path = \"tweets.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Applichiamo la parafrasi ai tweet\n",
        "data['paraphrased_text'] = data['text'].apply(paraphrase_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "SIsJPbu2voxJ",
        "outputId": "4d5c4dd4-ecf3-476b-a86a-4138abd6da97"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'lm_model_base' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2abb038f162c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerationConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_model_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhf_auth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_model_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhf_auth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lm_model_base' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import emoji\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Mappa delle etichette\n",
        "label_map = {0: 'Rabbia', 1: 'Gioia', 2: 'Ottimismo', 3: 'Tristezza'}\n",
        "\n",
        "\n",
        "emoji_freq = {emotion: Counter() for emotion in label_map.values()}\n",
        "total_emoji_count = Counter()\n",
        "\n",
        "# De-emojizzazione del testo\n",
        "data['text'] = data['text'].apply(lambda text: emoji.demojize(text, delimiters=(\" :\", \": \")))\n",
        "\n",
        "for _, row in data.iterrows():\n",
        "    text = row['text']\n",
        "    label = label_map[row['label']]\n",
        "\n",
        "    emojis = [word for word in text.split() if word.startswith(\":\") and word.endswith(\":\")]\n",
        "\n",
        "    for emj in emojis:\n",
        "        emoji_freq[label][emj] += 1\n",
        "        total_emoji_count[emj] += 1\n",
        "\n",
        "normalized_emoji_freq = {emotion: Counter() for emotion in emoji_freq.keys()}\n",
        "\n",
        "# Calcolo dello score logaritmico\n",
        "for emotion, counter in emoji_freq.items():\n",
        "    for emj, count in counter.items():\n",
        "        term_freq = count / total_emoji_count[emj]\n",
        "        log_weighted_freq = term_freq * np.log(total_emoji_count[emj] + 1)\n",
        "        normalized_emoji_freq[emotion][emj] = log_weighted_freq\n",
        "\n",
        "# Funzione per ottenere il vettore di punteggi per ogni tweet\n",
        "def get_tweet_emoji_vector(text):\n",
        "    emojis = [word for word in text.split() if word.startswith(\":\") and word.endswith(\":\")]\n",
        "\n",
        "    emotion_scores = {emotion: 0 for emotion in label_map.values()}\n",
        "\n",
        "    for emj in emojis:\n",
        "        for emotion in normalized_emoji_freq:\n",
        "            emotion_scores[emotion] += normalized_emoji_freq[emotion].get(emj, 0)\n",
        "\n",
        "    num_emojis = len(emojis)\n",
        "    if num_emojis > 0:\n",
        "        for emotion in emotion_scores:\n",
        "            emotion_scores[emotion] /= num_emojis\n",
        "\n",
        "    return list(emotion_scores.values())\n",
        "\n",
        "# Aggiungzione feature al dataset\n",
        "data['emoji_emotion_scores'] = data['text'].apply(get_tweet_emoji_vector)\n",
        "\n",
        "# Visualizzazione dei risultati\n",
        "for emotion, counter in normalized_emoji_freq.items():\n",
        "    top_emojis = counter.most_common(10)\n",
        "    emojis, freqs = zip(*top_emojis) if top_emojis else ([], [])\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=list(emojis), y=list(freqs), palette=\"viridis\")\n",
        "    plt.title(f\"Top 10 emoji (logaritmo pesato) per {emotion}\")\n",
        "    plt.xlabel(\"Emoji\")\n",
        "    plt.ylabel(\"Frequenza Logaritmica Pesata\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HdtXBMqe8fi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "8Cwr_zqd7boH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wTfu3Ru5BKVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_freq = {emotion: Counter() for emotion in label_map.values()}\n",
        "total_pos_count = Counter()\n",
        "\n",
        "for _, row in data.iterrows():\n",
        "    text = row['text']\n",
        "    label = label_map[row['label']]\n",
        "    tokens = word_tokenize(text)\n",
        "    tagged = pos_tag(tokens)\n",
        "\n",
        "    for _, tag in tagged:\n",
        "        pos_freq[label][tag] += 1\n",
        "        total_pos_count[tag] += 1\n",
        "\n",
        "# Normalizzazione PoS\n",
        "normalized_pos_freq = {emotion: Counter() for emotion in pos_freq.keys()}\n",
        "for emotion, counter in pos_freq.items():\n",
        "    for tag, count in counter.items():\n",
        "        term_freq = count / total_pos_count[tag]\n",
        "        log_weighted_freq = term_freq * np.log(total_pos_count[tag] + 1)\n",
        "        normalized_pos_freq[emotion][tag] = log_weighted_freq\n",
        "\n",
        "# Funzione per ottenere il vettore di punteggi per ogni tweet basato su PoS\n",
        "def get_tweet_pos_vector(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tagged = pos_tag(tokens)\n",
        "    emotion_scores = {emotion: 0 for emotion in label_map.values()}\n",
        "    for _, tag in tagged:\n",
        "        for emotion in normalized_pos_freq:\n",
        "            emotion_scores[emotion] += normalized_pos_freq[emotion].get(tag, 0)\n",
        "    num_tags = len(tagged)\n",
        "    if num_tags > 0:\n",
        "        for emotion in emotion_scores:\n",
        "            emotion_scores[emotion] /= num_tags\n",
        "    return list(emotion_scores.values())\n",
        "\n",
        "data['pos_emotion_scores'] = data['text'].apply(get_tweet_pos_vector)\n",
        "\n",
        "\n",
        "for emotion, counter in normalized_pos_freq.items():\n",
        "    top_pos = counter.most_common(10)\n",
        "    pos_tags, freqs = zip(*top_pos) if top_pos else ([], [])\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=list(pos_tags), y=list(freqs), palette=\"magma\")\n",
        "    plt.title(f\"Top 10 PoS (logaritmo pesato) per {emotion}\")\n",
        "    plt.xlabel(\"Parti del discorso\")\n",
        "    plt.ylabel(\"Frequenza Logaritmica Pesata\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "-eMRWiuRAUTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "BrpoJNJ8A79L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5xNLBBlFOZi"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# Funzione per contare i PoS\n",
        "def extract_pos_counts(text):\n",
        "    tokens = word_tokenize(text)  # Tokenizza il testo\n",
        "    tagged = pos_tag(tokens)\n",
        "    pos_counts = [0, 0, 0, 0]\n",
        "\n",
        "    for _, tag in tagged:\n",
        "        if tag.startswith('JJ'):    # Aggettivi\n",
        "            pos_counts[0] += 1\n",
        "        elif tag.startswith('VB'):  # Verbi\n",
        "            pos_counts[1] += 1\n",
        "        elif tag.startswith('NN'):  # Sostantivi\n",
        "            pos_counts[2] += 1\n",
        "        elif tag.startswith('RB'):  # Avverbi\n",
        "            pos_counts[3] += 1\n",
        "    return pos_counts\n",
        "\n",
        "\n",
        "# Applicare la funzione e creare una lista di conteggi\n",
        "data['pos_counts'] = data['text'].apply(extract_pos_counts)\n",
        "\n",
        "df_pos = pd.DataFrame(data['pos_counts'].tolist(), columns=['JJ', 'VB', 'NN', 'RB'])\n",
        "data = pd.concat([data, df_pos], axis=1)\n",
        "data = data.drop(columns=['pos_counts'])\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "pos_map = {\n",
        "    'JJ': 'Aggettivi',\n",
        "    'NN': 'Sostantivi',\n",
        "    'RB': 'Avverbi',\n",
        "}\n",
        "\n",
        "word_freq = {emotion: Counter() for emotion in ['Rabbia', 'Gioia', 'Ottimismo', 'Tristezza']}\n",
        "total_word_count = Counter()\n",
        "\n",
        "label_map = {0: 'Rabbia', 1: 'Gioia', 2: 'Ottimismo', 3: 'Tristezza'}\n",
        "\n",
        "\n",
        "for _, row in data.iterrows():\n",
        "    text = row['text']\n",
        "    label = label_map[row['label']]\n",
        "\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words and not word.startswith('#')]\n",
        "\n",
        "    tagged_words = pos_tag(tokens)\n",
        "\n",
        "    for word, pos in tagged_words:\n",
        "        if pos in pos_map:\n",
        "            word_freq[label][word] += 1\n",
        "            total_word_count[word] += 1\n",
        "\n",
        "normalized_word_freq = {emotion: Counter() for emotion in word_freq.keys()}\n",
        "\n",
        "for emotion, counter in word_freq.items():\n",
        "    for word, count in counter.items():\n",
        "        term_freq = count / total_word_count[word]\n",
        "        log_weighted_freq = term_freq * np.log(total_word_count[word] + 1)\n",
        "        normalized_word_freq[emotion][word] = log_weighted_freq\n",
        "\n",
        "for emotion, counter in normalized_word_freq.items():\n",
        "    print(f\"\\nTop 10 parole con logaritmo pesato per {emotion}:\")\n",
        "    for word, freq in counter.most_common(10):\n",
        "        print(f\"{word}: {freq:.4f}\")\n",
        "\n",
        "for emotion, counter in normalized_word_freq.items():\n",
        "    top_words = counter.most_common(20)\n",
        "    words, freqs = zip(*top_words)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=list(words), y=list(freqs), palette=\"viridis\")\n",
        "    plt.title(f\"Top 10 parole (logaritmo pesato) per {emotion}\")\n",
        "    plt.xlabel(\"Parole\")\n",
        "    plt.ylabel(\"Frequenza Logaritmica Pesata\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "9uh_SCrChn_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_freq = {emotion: Counter() for emotion in ['Rabbia', 'Gioia', 'Ottimismo', 'Tristezza']}\n",
        "total_word_count = Counter()\n",
        "\n",
        "for _, row in data.iterrows():\n",
        "    text = row['text']\n",
        "    label = label_map[row['label']]\n",
        "\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    tagged_words = pos_tag(tokens)\n",
        "    for word, pos in tagged_words:\n",
        "        if pos in pos_map:\n",
        "            word_freq[label][word] += 1\n",
        "            total_word_count[word] += 1\n",
        "\n",
        "\n",
        "normalized_word_freq = {emotion: Counter() for emotion in word_freq.keys()}\n",
        "\n",
        "for emotion, counter in word_freq.items():\n",
        "    for word, count in counter.items():\n",
        "        term_freq = count / total_word_count[word]\n",
        "        log_weighted_freq = term_freq * np.log(total_word_count[word] + 1)\n",
        "        normalized_word_freq[emotion][word] = log_weighted_freq\n",
        "\n",
        "\n",
        "def get_tweet_vector(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    emotion_scores = {'Rabbia': 0, 'Gioia': 0, 'Ottimismo': 0, 'Tristezza': 0}\n",
        "\n",
        "    for word in tokens:\n",
        "        for emotion in normalized_word_freq:\n",
        "            emotion_scores[emotion] += normalized_word_freq[emotion].get(word, 0)\n",
        "\n",
        "    num_words = len(tokens)\n",
        "    if num_words > 0:\n",
        "        for emotion in emotion_scores:\n",
        "            emotion_scores[emotion] /= num_words\n",
        "    return list(emotion_scores.values())\n",
        "\n",
        "tweet_vectors = []\n",
        "for _, row in data.iterrows():\n",
        "    tweet_vector = get_tweet_vector(row['text'])\n",
        "    tweet_vectors.append(tweet_vector)\n",
        "\n",
        "tweet_feature_data = pd.DataFrame(tweet_vectors, columns=['Rabbia', 'Gioia', 'Ottimismo', 'Tristezza'])\n",
        "\n",
        "data['words_emotion_scores'] = tweet_feature_data.values.tolist()\n",
        "data"
      ],
      "metadata": {
        "id": "gZXIgPCXOxvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpvCjuWkFOZk"
      },
      "outputs": [],
      "source": [
        "data['word_count'] = data['text'].apply(lambda x: len(x.split())) # quantità di parole\n",
        "data['text_length'] = data['text'].apply(len)                     # lunghezza del testo\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "data['hashtags'] = data['text'].apply(lambda x: re.findall(r\"#\\w+\", x.lower()))\n",
        "\n",
        "hashtag_freq = {emotion: Counter() for emotion in ['Rabbia', 'Gioia', 'Ottimismo', 'Tristezza']}\n",
        "total_hashtag_count = Counter()\n",
        "\n",
        "for _, row in data.iterrows():\n",
        "    hashtags = row['hashtags']\n",
        "    label = label_map[row['label']]\n",
        "\n",
        "    for hashtag in hashtags:\n",
        "        hashtag_freq[label][hashtag] += 1\n",
        "        total_hashtag_count[hashtag] += 1\n",
        "normalized_hashtag_freq = {emotion: Counter() for emotion in hashtag_freq.keys()}\n",
        "\n",
        "for emotion, counter in hashtag_freq.items():\n",
        "    for hashtag, count in counter.items():\n",
        "        term_freq = count / total_hashtag_count[hashtag]\n",
        "        log_weighted_freq = term_freq * np.log(total_hashtag_count[hashtag] + 1)\n",
        "        normalized_hashtag_freq[emotion][hashtag] = log_weighted_freq\n",
        "\n",
        "for emotion, counter in normalized_hashtag_freq.items():\n",
        "    print(f\"\\nTop 10 hashtag con logaritmo pesato per {emotion}:\")\n",
        "    for hashtag, freq in counter.most_common(10):\n",
        "        print(f\"{hashtag}: {freq:.4f}\")\n",
        "\n",
        "for emotion, counter in normalized_hashtag_freq.items():\n",
        "    top_hashtags = counter.most_common(20)\n",
        "    hashtags, freqs = zip(*top_hashtags)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=list(hashtags), y=list(freqs), palette=\"viridis\")\n",
        "    plt.title(f\"Top 10 hashtag (logaritmo pesato) per {emotion}\")\n",
        "    plt.xlabel(\"Hashtag\")\n",
        "    plt.ylabel(\"Frequenza Logaritmica Pesata\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "DmVTnk4RkImM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hashtag_vector(hashtags):\n",
        "    emotion_scores = {'Rabbia': 0, 'Gioia': 0, 'Ottimismo': 0, 'Tristezza': 0}\n",
        "\n",
        "    for hashtag in hashtags:\n",
        "        for emotion in normalized_hashtag_freq:\n",
        "            emotion_scores[emotion] += normalized_hashtag_freq[emotion].get(hashtag, 0)\n",
        "    return list(emotion_scores.values())\n",
        "data['hastag_emotion_scores'] = data['hashtags'].apply(get_hashtag_vector)\n",
        "data = data.drop(columns=['hashtags'])\n",
        "\n"
      ],
      "metadata": {
        "id": "cnH5dV3xoeMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "q8aurjqspHbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX9to0G5FOZq"
      },
      "outputs": [],
      "source": [
        "enc = OrdinalEncoder()\n",
        "labels = data[\"label\"]\n",
        "data2 = data.drop(\"text\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data2['JJ'] = [x[0] for x in data['pos_counts']]\n",
        "#data2['VB'] = [x[1] for x in data['pos_counts']]\n",
        "#data2['NN'] = [x[2] for x in data['pos_counts']]\n",
        "#data2['RB'] = [x[3] for x in data['pos_counts']]\n",
        "data2['emoji_rabbia_scores'] = [x[0] for x in data['emoji_emotion_scores']]\n",
        "data2['emoji_gioia_scores'] = [x[1] for x in data['emoji_emotion_scores']]\n",
        "data2['emoji_optym_scores'] = [x[2] for x in data['emoji_emotion_scores']]\n",
        "data2['emoji_tristezza_scores'] = [x[3] for x in data['emoji_emotion_scores']]\n",
        "data2['word_rabbia_scores'] = [x[0] for x in data['words_emotion_scores']]\n",
        "data2['word_gioia_scores'] = [x[1] for x in data['words_emotion_scores']]\n",
        "data2['word_optym_scores'] = [x[2] for x in data['words_emotion_scores']]\n",
        "data2['word_tristezza_scores'] = [x[3] for x in data['words_emotion_scores']]\n",
        "data2['hastag_rabbia_scores'] = [x[0] for x in data['hastag_emotion_scores']]\n",
        "data2['hastag_gioia_scores'] = [x[1] for x in data['hastag_emotion_scores']]\n",
        "data2['hastag_optym_scores'] = [x[2] for x in data['hastag_emotion_scores']]\n",
        "data2['hastag_tristezza_scores'] = [x[3] for x in data['hastag_emotion_scores']]\n",
        "data2['pos_rabbia_scores'] = [x[0] for x in data['pos_emotion_scores']]\n",
        "data2['pos_gioia_scores'] = [x[1] for x in data['pos_emotion_scores']]\n",
        "data2['pos_optym_scores'] = [x[2] for x in data['pos_emotion_scores']]\n",
        "data2['pos_tristezza_scores'] = [x[3] for x in data['pos_emotion_scores']]"
      ],
      "metadata": {
        "id": "wyAvG2zytjFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = data2.drop(columns=['emoji_emotion_scores','words_emotion_scores','hastag_emotion_scores', 'pos_emotion_scores'])\n",
        "data2.info()"
      ],
      "metadata": {
        "id": "5qAAksN3yhr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2"
      ],
      "metadata": {
        "id": "sdwYP4CwFDFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhAKCy_HFOZr"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(data2.corr(), cmap=\"coolwarm\", annot=True, fmt=\".1f\")\n",
        "plt.title(\"Matrice di correlazione tra le feature\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "parameters = {\n",
        "    'n_estimators':[100, 150, 200],\n",
        "    'criterion':('gini', 'entropy', 'log_loss'),\n",
        "    'max_depth':[5, 10, 20, None]\n",
        "}\n",
        "\n",
        "forest = RandomForestClassifier(random_state=42)\n",
        "grid = GridSearchCV(forest, parameters, scoring='accuracy') # mi serve per trovare le migliori combinazioni di iperparametri\n",
        "grid.fit(data2, labels) # addestro la gridSearch\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "best_accuracy = grid.best_score_\n",
        "best_params = grid.best_params_\n",
        "print(f'Il miglior modello ha accuracy {best_accuracy} ed i suoi migliori parametri sono {best_params}')"
      ],
      "metadata": {
        "id": "lCebHOfPKaeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "sf = SelectFromModel(estimator=best_model)\n",
        "sf.fit_transform(data2, labels)\n",
        "print(sf.get_feature_names_out())"
      ],
      "metadata": {
        "id": "GlXgKdTQfrZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TM_x-QFMFOZs"
      },
      "outputs": [],
      "source": [
        "#Ricreo il dataset finale con le feature estratte + il testo completo\n",
        "data3 = data2[['word_rabbia_scores','word_gioia_scores', 'word_optym_scores', 'word_tristezza_scores']]\n",
        "data3.insert(0, \"text\", data[\"text\"])\n",
        "data3.insert(5, \"label\",labels)\n",
        "data3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Szadz-0KvTdy"
      },
      "outputs": [],
      "source": [
        "x_train = data3['text']\n",
        "y_train = data3['label']\n",
        "word_rabbia_scores = data3['word_rabbia_scores']\n",
        "word_gioia_scores = data3['word_gioia_scores']\n",
        "word_optym_scores = data3['word_optym_scores']\n",
        "word_tristezza_scores = data3['word_tristezza_scores']\n",
        "\n",
        "with open(\"/content/drive/MyDrive/NLP/Challenge_2024/emotion/val_text.txt\", 'r', encoding='utf-8') as f:\n",
        "    tweets = f.readlines()\n",
        "\n",
        "# Rimuovi eventuali spazi vuoti o newline\n",
        "tweets = [tweet.strip() for tweet in tweets]\n",
        "val_text_df = pd.DataFrame(tweets, columns=['text'])\n",
        "\n",
        "with open(\"/content/drive/MyDrive/NLP/Challenge_2024/emotion/val_labels.txt\", 'r', encoding='utf-8') as f:\n",
        "    labels = f.readlines()\n",
        "\n",
        "labels2 = [int(label.strip()) for label in labels]\n",
        "\n",
        "val_data = pd.DataFrame(tweets, columns=['text'])\n",
        "val_data['label'] = labels2\n",
        "val_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applicazione della funzione ai tweet e creazione delle feature\n",
        "tweet_vectors = []\n",
        "for _, row in val_data.iterrows():\n",
        "    tweet_vector = get_tweet_vector(row['text'])\n",
        "    tweet_vectors.append(tweet_vector)\n",
        "\n",
        "# Convertilo in un DataFrame per visualizzare le feature\n",
        "tweet_feature_data = pd.DataFrame(tweet_vectors, columns=['Rabbia', 'Gioia', 'Ottimismo', 'Tristezza'])\n",
        "val_data['words_emotion_scores'] = tweet_feature_data.values.tolist()\n",
        "\n",
        "val_data['word_rabbia_scores'] = [x[0] for x in val_data['words_emotion_scores']]\n",
        "val_data['word_gioia_scores'] = [x[1] for x in val_data['words_emotion_scores']]\n",
        "val_data['word_optym_scores'] = [x[2] for x in val_data['words_emotion_scores']]\n",
        "val_data['word_tristezza_scores'] = [x[3] for x in val_data['words_emotion_scores']]\n",
        "val_data = val_data.drop(columns=['words_emotion_scores'])\n",
        "val_data\n"
      ],
      "metadata": {
        "id": "yo1rRV6-_0t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47XiljIZFOZu"
      },
      "outputs": [],
      "source": [
        "x_val = val_data['text']\n",
        "word_rabbia_scores_val = val_data['word_rabbia_scores']\n",
        "word_gioia_scores_val = val_data['word_gioia_scores']\n",
        "word_optym_scores_val = val_data['word_optym_scores']\n",
        "word_tristezza_scores_val = val_data['word_tristezza_scores']\n",
        "label_val = val_data['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvhPl5xJFOZv"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.apply(lambda x: x.replace('\\r', ' ').replace('\\n', ' '))\n",
        "x_val = x_val.apply(lambda x: x.replace('\\r', ' ').replace('\\n', ' '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tD5mdgsmvUPV"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, x, word_rabbia_scores, word_gioia_scores, word_optym_scores, word_tristezza_scores, y, stopwords):\n",
        "\n",
        "        # x e y sono series di pandas\n",
        "        tokens_litt = [nltk.word_tokenize(text, language='english')\n",
        "         for text in list(x)]\n",
        "        text_clean = []\n",
        "\n",
        "        if stopwords:\n",
        "            for sentence in tqdm(tokens_litt, desc='Tokenizing ... '):\n",
        "                text_clean.append(' '.join([w.lower() for w in sentence if\n",
        "                    not w.lower() in nltk.corpus.stopwords.words(\"english\")]))\n",
        "        else:\n",
        "            for sentence in tqdm(tokens_litt, desc='Tokenizing ... '):\n",
        "                text_clean.append(' '.join([w.lower() for w in sentence]))\n",
        "            # ogni token è separato dall'altro con uno spazio\n",
        "\n",
        "        self.texts = text_clean\n",
        "        self.labels = [torch.tensor(label) for label in y]\n",
        "        self.word_rabbia_scores = [torch.tensor(score) for score in word_rabbia_scores]\n",
        "        self.word_gioia_scores = [torch.tensor(score) for score in word_gioia_scores]\n",
        "        self.word_optym_scores = [torch.tensor(score) for score in word_optym_scores]\n",
        "        self.word_tristezza_scores = [torch.tensor(score) for score in word_tristezza_scores]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.texts[idx]\n",
        "        batch_labels = np.array(self.labels[idx])\n",
        "        batch_word_rabbia_scores = np.array(self.word_rabbia_scores[idx])\n",
        "        batch_word_gioia_scores = np.array(self.word_gioia_scores[idx])\n",
        "        batch_word_optym_scores = np.array(self.word_optym_scores[idx])\n",
        "        batch_word_tristezza_scores = np.array(self.word_tristezza_scores[idx])\n",
        "\n",
        "        return batch_texts, batch_word_rabbia_scores, batch_word_gioia_scores, batch_word_optym_scores, batch_word_tristezza_scores, batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6f350WTveW6"
      },
      "outputs": [],
      "source": [
        "#Iperparametri della rete\n",
        "#Uso il modello bertweet-base\n",
        "hyperparameters = {\n",
        "    \"epochs\": 5,\n",
        "    \"learning_rate\": 1e-5,\n",
        "    \"batch_size\": 16,\n",
        "    \"dropout\": 0.1,\n",
        "    \"stopwords\": False,\n",
        "    \"language_model\": \"vinai/bertweet-base\",\n",
        "    \"layers\": 1,\n",
        "    \"h_dim\": 768,\n",
        "    \"bilstm\": True,\n",
        "    \"patience\": 5,\n",
        "    \"min_delta\": 0.01,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sunjLJSRvh1Y"
      },
      "outputs": [],
      "source": [
        "#!pip install emoji\n",
        "#Installo la libreria emoji per trasformare le emoji di un testo in caratteri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPsJaVy-FOZw"
      },
      "outputs": [],
      "source": [
        "#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_rabbia_scores_val = val_data['word_rabbia_scores']\n",
        "word_gioia_scores_val = val_data['word_gioia_scores']\n",
        "word_optym_scores_val = val_data['word_optym_scores']\n",
        "word_tristezza_scores_val = val_data['word_tristezza_scores']"
      ],
      "metadata": {
        "id": "KX1a9opgBxlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLm381m5vkqQ"
      },
      "outputs": [],
      "source": [
        "#creo i dataset\n",
        "train_dataset = Dataset(x_train, word_rabbia_scores, word_gioia_scores, word_optym_scores, word_tristezza_scores, y_train, hyperparameters[\"stopwords\"])\n",
        "val_dataset = Dataset(x_val, word_rabbia_scores_val, word_gioia_scores_val, word_optym_scores_val, word_tristezza_scores_val ,label_val, hyperparameters[\"stopwords\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkpEKxbKvmYc"
      },
      "outputs": [],
      "source": [
        "extra_features = 4\n",
        "\n",
        "class ClassifierDeep(nn.Module):\n",
        "    def __init__(self, labels, hdim, dropout, model_name):\n",
        "        super(ClassifierDeep, self).__init__()\n",
        "        config = AutoConfig.from_pretrained(model_name)\n",
        "        self.lm_model = AutoModel.from_pretrained(model_name, config=config)\n",
        "\n",
        "        # Proiezione dell'output di BERT\n",
        "        self.bert_projection = nn.Sequential(\n",
        "            nn.Linear(hdim, hdim),\n",
        "            nn.BatchNorm1d(hdim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # Proiezione delle extra features\n",
        "        self.extra_feature_projection = nn.Sequential(\n",
        "            nn.Linear(extra_features, hdim // 2),\n",
        "            nn.BatchNorm1d(hdim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # Classificatore finale\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hdim + (hdim // 2), hdim),\n",
        "            nn.BatchNorm1d(hdim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hdim, labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_id_text, attention_mask, word_rabbia_scores, word_gioia_scores, word_optym_scores, word_tristezza_scores):\n",
        "\n",
        "        # Output da BERT\n",
        "        output = self.lm_model(input_id_text, attention_mask).last_hidden_state\n",
        "        output = output[:, 0, :]  # CLS token\n",
        "        output = self.bert_projection(output)\n",
        "\n",
        "        # Extra features (PoS, emoji scores)\n",
        "        extra_features = torch.cat((word_rabbia_scores.unsqueeze(1), word_gioia_scores.unsqueeze(1),\n",
        "                                    word_optym_scores.unsqueeze(1), word_tristezza_scores.unsqueeze(1)), dim=1)\n",
        "        extra_features = self.extra_feature_projection(extra_features)\n",
        "\n",
        "        # Fusione delle rappresentazioni\n",
        "        combined = torch.cat((output, extra_features), dim=1)\n",
        "        return self.classifier(combined)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wnprxd_nvm9G"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0.0):\n",
        "\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta              # valore minimo di decrescita della loss di validazione all'epoca corrente\n",
        "                                                # per asserire che c'è un miglioramento della loss\n",
        "        self.counter = 0                        # contatore delle epoche di pazienza\n",
        "        self.early_stop = False                 # flag di early stop\n",
        "        self.min_validation_loss = torch.inf    # valore corrente ottimo della loss di validazione\n",
        "\n",
        "    def __call__(self, validation_loss):\n",
        "        # chiamata in forma funzionale dell'oggetto di classe EarlySopping\n",
        "\n",
        "        if (validation_loss + self.min_delta) >= self.min_validation_loss:  # la loss di validazione non decresce\n",
        "            self.counter += 1                                               # incrementiamo il contatore delle epoche di pazienza\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                print(\"Early stop!\")\n",
        "        else:                                               # c'è un miglioramento della loss:\n",
        "            self.min_validation_loss = validation_loss      # consideriamo la loss corrente\n",
        "                                                            # come nuova loss ottimale\n",
        "            self.counter = 0                                # e azzeriamo il contatore di pazienza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYNopA4Rvr5s"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, dataloader, tokenizer, loss, optimizer, device):\n",
        "    model.train()\n",
        "\n",
        "    epoch_acc = 0\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch_texts, batch_word_rabbia_scores, batch_word_gioia_scores, batch_word_optym_scores, batch_word_tristezza_scores, batch_labels in tqdm(dataloader, desc='training set'):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tokens = tokenizer(list(batch_texts), add_special_tokens=True, return_tensors='pt', padding='max_length', max_length = 128, truncation=True)\n",
        "        input_id_texts = tokens['input_ids'].squeeze(1).to(device)\n",
        "        batch_word_rabbia_scores = batch_word_rabbia_scores.float().to(device)\n",
        "        batch_word_gioia_scores = batch_word_gioia_scores.float().to(device)\n",
        "        batch_word_optym_scores = batch_word_optym_scores.float().to(device)\n",
        "        batch_word_tristezza_scores = batch_word_tristezza_scores.float().to(device)\n",
        "\n",
        "        mask_texts = tokens['attention_mask'].squeeze(1).to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "        output = model(input_id_texts, mask_texts, batch_word_rabbia_scores, batch_word_gioia_scores, batch_word_optym_scores, batch_word_tristezza_scores).squeeze(1)\n",
        "\n",
        "        # la loss è una CrossEntropyLoss, al suo interno ha\n",
        "        # la logsoftmax + negative log likelihood loss\n",
        "        batch_loss = loss(output, batch_labels)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += batch_loss.item()\n",
        "\n",
        "        # per calcolare l'accuracy devo generare le predizioni\n",
        "        # applicando manualmente la logsoftmax\n",
        "        #softmax = nn.LogSoftmax(dim=1)\n",
        "        #epoch_acc += (softmax(output).argmax(dim=1) == batch_labels).sum().item()\n",
        "        preds = output.argmax(dim=1)\n",
        "        epoch_acc += (preds == batch_labels).sum().item()\n",
        "\n",
        "        batch_labels = batch_labels.detach().cpu()\n",
        "        input_id_texts = input_id_texts.detach().cpu()\n",
        "        mask_texts = mask_texts.detach().cpu()\n",
        "        batch_word_rabbia_scores = batch_word_rabbia_scores.detach().cpu()\n",
        "        batch_word_gioia_scores = batch_word_gioia_scores.detach().cpu()\n",
        "        batch_word_optym_scores = batch_word_optym_scores.detach().cpu()\n",
        "        batch_word_tristezza_scores = batch_word_tristezza_scores.detach().cpu()\n",
        "\n",
        "        output = output.detach().cpu()\n",
        "\n",
        "    return epoch_loss / len(dataloader), epoch_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCY_fzlZvzRA"
      },
      "outputs": [],
      "source": [
        "def test_loop(model, dataloader, tokenizer, loss, device, scheduler):\n",
        "    model.eval()\n",
        "\n",
        "    epoch_acc = 0\n",
        "    epoch_loss = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch_texts, batch_word_rabbia_scores, batch_word_gioia_scores, batch_word_optym_scores, batch_word_tristezza_scores, batch_labels in tqdm(dataloader, desc='dev set'):\n",
        "\n",
        "            tokens = tokenizer(list(batch_texts), add_special_tokens=True, return_tensors='pt', padding='max_length', max_length = 128, truncation=True)\n",
        "            input_id_texts = tokens['input_ids'].squeeze(1).to(device)\n",
        "            batch_word_rabbia_scores = batch_word_rabbia_scores.float().to(device)\n",
        "            batch_word_gioia_scores = batch_word_gioia_scores.float().to(device)\n",
        "            batch_word_optym_scores = batch_word_optym_scores.float().to(device)\n",
        "            batch_word_tristezza_scores = batch_word_tristezza_scores.float().to(device)\n",
        "\n",
        "            mask_texts = tokens['attention_mask'].squeeze(1).to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "            output = model(input_id_texts, mask_texts, batch_word_rabbia_scores, batch_word_gioia_scores, batch_word_optym_scores, batch_word_tristezza_scores).squeeze(1)\n",
        "\n",
        "            # la loss è una CrossEntropyLoss, al suo interno ha\n",
        "            # la logsoftmax + negative log likelihood loss\n",
        "            batch_loss = loss(output, batch_labels)\n",
        "            epoch_loss += batch_loss.item()\n",
        "\n",
        "            # per calcolare l'accuracy devo generare le predizioni\n",
        "            # applicando manualmente la logsoftmax\n",
        "            #softmax = nn.LogSoftmax(dim=1)\n",
        "            #preds = softmax(output).argmax(dim=1)\n",
        "            #epoch_acc += (preds == batch_labels).sum().item()\n",
        "            preds = output.argmax(dim=1)\n",
        "            epoch_acc += (preds == batch_labels).sum().item()\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "            batch_labels = batch_labels.detach().cpu()\n",
        "            input_id_texts = input_id_texts.detach().cpu()\n",
        "            mask_texts = mask_texts.detach().cpu()\n",
        "            batch_word_rabbia_scores = batch_word_rabbia_scores.detach().cpu()\n",
        "            batch_word_gioia_scores = batch_word_gioia_scores.detach().cpu()\n",
        "            batch_word_optym_scores = batch_word_optym_scores.detach().cpu()\n",
        "            batch_word_tristezza_scores = batch_word_tristezza_scores.detach().cpu()\n",
        "\n",
        "            output = output.detach().cpu()\n",
        "    scheduler.step(epoch_loss)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    return epoch_loss / len(dataloader), epoch_acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VpZgPgyvz7f"
      },
      "outputs": [],
      "source": [
        "def train_test(model, epochs, optimizer, device, train_data,\n",
        "               batch_size, model_name, train_loss_fn,\n",
        "               test_loss_fn=None,         # non necessariamente train e test loss devono differire\n",
        "               early_stopping=None,       # posso addstrare senza early stopping\n",
        "               val_data=None,             # e in questo caso non c'è validation set\n",
        "               scheduler=None):           # possibile scheduler per monitorare l'andamento di un iperparametro,\n",
        "                                          # tipicamente il learning rate\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "    #test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "    # check sulle funzioni di loss\n",
        "    if test_loss_fn == None:\n",
        "        test_loss_fn = train_loss_fn\n",
        "\n",
        "    # liste dei valori di loss e accuracy epoca per epoca per il plot\n",
        "    train_loss = []\n",
        "    validation_loss = []\n",
        "    test_loss = []\n",
        "\n",
        "    train_acc = []\n",
        "    validation_acc = []\n",
        "    test_acc = []\n",
        "\n",
        "    preds = []\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    #tokenizer = DebertaV2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Ciclo di addestramento con early stopping\n",
        "    for epoch in tqdm(range(1,epochs+1)):\n",
        "\n",
        "        epoch_train_loss, epoch_train_acc = train_loop(model, train_dataloader, tokenizer, train_loss_fn, optimizer, device)\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc/len(train_data))\n",
        "\n",
        "        # validation se è presente la callback di early stopping\n",
        "        if early_stopping != None:\n",
        "                epoch_validate_loss, epoch_validate_acc, f1 = test_loop(model, val_dataloader, tokenizer, test_loss_fn, device, scheduler)\n",
        "                validation_loss.append(epoch_validate_loss)\n",
        "                validation_acc.append(epoch_validate_acc/len(val_data))\n",
        "\n",
        "        # test\n",
        "        #epoch_test_loss, epoch_test_acc, f1 = test_loop(model, test_dataloader, tokenizer, test_loss_fn, device)\n",
        "        #test_loss.append(epoch_test_loss)\n",
        "        #test_acc.append(epoch_test_acc/len(test_data))\n",
        "\n",
        "        val_loss_str = f'Validation loss: {epoch_validate_loss:6.4f} 'if early_stopping != None else ' '\n",
        "        val_acc_str = f'Validation accuracy: {(epoch_validate_acc/len(val_data)):6.4f} ' if early_stopping != None else ' '\n",
        "        print(f\"\\nF1 score: {f1:.4f}\")\n",
        "        print(f\"\\nTrain loss: {epoch_train_loss:6.4f} ---- {val_loss_str}\")\n",
        "        print(f\"Train accuracy: {(epoch_train_acc/len(train_data)):6.4f} ---- {val_acc_str}\")\n",
        "\n",
        "        # early stopping\n",
        "        if early_stopping != None:\n",
        "                early_stopping(epoch_validate_loss)\n",
        "                if early_stopping.early_stop:\n",
        "                    break\n",
        "\n",
        "    return train_loss, validation_loss, train_acc, validation_acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dos_MLiCFOaJ"
      },
      "outputs": [],
      "source": [
        "#GRID SEARCH PER TROVARE I PARAMETRI MIGLIORI\n",
        "param_grid = {\n",
        "    \"epochs\":[20],\n",
        "    \"learning_rate\": [1e-3],\n",
        "    \"batch_size\": [32],\n",
        "    \"dropout\": [0.2],\n",
        "    \"weight_decay\": [0.0001]\n",
        "}\n",
        "\n",
        "best_f1 = 0\n",
        "best_train_loss = 0\n",
        "best_val_loss = 0\n",
        "best_train_acc = 0\n",
        "best_val_acc = 0\n",
        "best_params={}\n",
        "f1_value=0\n",
        "\n",
        "grid = ParameterGrid(param_grid)\n",
        "for params in grid:\n",
        "  print(\"----------------------------------------------------------------\")\n",
        "  print(params)\n",
        "  # Acquisiamo il device su cui effettueremo il training\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Using {device} device\")\n",
        "\n",
        "  model = ClassifierDeep(numLabels,\n",
        "                      hyperparameters[\"h_dim\"],\n",
        "                      params[\"dropout\"],\n",
        "                      hyperparameters[\"language_model\"]).to(device)\n",
        "\n",
        "  print(model)\n",
        "\n",
        "  # Calcoliamo il numero totale dei parametri del modello\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  print(f\"Numero totale dei parametri: {total_params}\")\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = AdamW(model.parameters(), lr=params[\"learning_rate\"], weight_decay=params[\"weight_decay\"])\n",
        "  scheduler = torch.optim.lr_scheduler.LinearLR(optimizer=optimizer, start_factor=1, end_factor=0.1, total_iters=5)\n",
        "\n",
        "  # Creiamo la callback di early stopping da passare al nostro metodo di addestramento\n",
        "  early_stopping = EarlyStopping(patience=hyperparameters['patience'], min_delta=hyperparameters['min_delta'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  train_loss, validation_loss, train_acc, validation_acc, f1_value = train_test(model,\n",
        "                                                                                params['epochs'],\n",
        "                                                                                optimizer, device, train_dataset,\n",
        "                                                                                params['batch_size'], hyperparameters['language_model'],\n",
        "                                                                                criterion, criterion, early_stopping,val_dataset, scheduler=scheduler)\n",
        "\n",
        "  if f1_value > best_f1:\n",
        "    best_f1 = f1_value\n",
        "    best_params = copy.deepcopy(params)\n",
        "    best_train_loss = train_loss\n",
        "    best_val_loss = validation_loss\n",
        "    best_train_acc = train_acc\n",
        "    best_val_acc = validation_acc\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1obPVixjFOaK"
      },
      "outputs": [],
      "source": [
        "print(\"Parametri best F1:\\n\")\n",
        "print(f\"F1 score: {best_f1:.4f}\\n\")\n",
        "print(f\"Iperparametri migliori: {params}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6cNZDeawBfC"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "axs[0].plot(best_train_loss, label='training loss')\n",
        "axs[0].plot(best_val_loss, label='validation loss')\n",
        "axs[0].legend(loc='upper right')\n",
        "axs[0].set_ylim(0,1)\n",
        "\n",
        "axs[1].plot(best_train_acc, label='training accuracy')\n",
        "axs[1].plot(best_val_acc, label='validation accuracy')\n",
        "axs[1].legend(loc='lower right')\n",
        "axs[1].set_ylim(0,1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"modello_completo.pth\")\n"
      ],
      "metadata": {
        "id": "bqPKDYvXRx_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"modello_pesi.pth\")\n"
      ],
      "metadata": {
        "id": "22gh9dI4R0wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "osD8vOUrV69j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PQycPT3bpDPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NYufLagzpDNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kNqb_d_xpDK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwQKGXNkpDHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = \"Shit getting me irritated 😠\"\n",
        "print(\"Tweet originale:\", tweet)\n",
        "print(\"Tweet parafrasato:\", paraphrase_text(tweet))\n"
      ],
      "metadata": {
        "id": "aGFxKGMlpJq1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}